{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import src.preprocessing as preprocessing\n",
    "from src.preprocessing import preprocess, preprocess_players, polynomial_features\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, RidgeClassifierCV, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from src.build_db import connect\n",
    "from src.db_helpers import parse_date\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.decomposition import PCA, NMF, TruncatedSVD\n",
    "from scipy.sparse import coo_matrix, csc_matrix, hstack\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# connect to db\n",
    "db_name = 'dota_db'\n",
    "with open(os.path.expanduser('~/.pgpass')) as f:\n",
    "    for line in f:\n",
    "        host, port, db, user, password = [x.strip() for x in line.split(':')]\n",
    "        if db == db_name:\n",
    "            dota_con, meta = connect(user=user, password=password, db=db, host=host, port=port)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT DISTINCT ON(match_id) match_id, players, radiant_win FROM match_history WHERE duration >= 900;\n",
    "'''\n",
    "df = pd.read_sql(query, dota_con)\n",
    "df = preprocess_players(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df['radiant_win'].values\n",
    "X = df.drop(['radiant_win', 'match_id'], axis=1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=5000)\n",
    "X_poly_train = polynomial_features(X_train)\n",
    "X_poly_test = polynomial_features(X_test)\n",
    "X_poly = polynomial_features(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synergy and Countering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def synergy_matrix(X, y):\n",
    "    winrates = np.ones((114,114)) * .5\n",
    "    for i in xrange(0, 113):\n",
    "        for j in xrange(i + 1, 114):\n",
    "            radiant_matches = (X[:, i] == 1) & (X[:, j + 114] == 1)\n",
    "            dire_matches = (X[:, j] == 1) & (X[:, i + 114] == 1)\n",
    "            try:\n",
    "                wr = (y[radiant_matches].sum() +\\\n",
    "                    (y[dire_matches].shape[0] - y[dire_matches].sum()) )\\\n",
    "                    / (radiant_matches.sum() + dire_matches.sum())\n",
    "            except ZeroDivisionError:\n",
    "                wr = .5\n",
    "            if np.isnan([wr]):\n",
    "                wr = .5\n",
    "            winrates[i, j] = wr\n",
    "            winrates[j, i] = wr\n",
    "    return winrates\n",
    "\n",
    "def counter_matrix(X, y):\n",
    "    winrates = np.ones((114, 114)) * .5\n",
    "    for i in xrange(0, 113):\n",
    "        for j in xrange(i + 1, 114):\n",
    "            radiant_matches = (X[:, i] == 1) & (X[:, j + 114] == 1)\n",
    "            dire_matches = (X[:, j] == 1) & (X[:, i + 114] == 1)\n",
    "            try:\n",
    "                wr = (y[radiant_matches].sum() +\\\n",
    "                     (y[dire_matches].shape[0] - y[dire_matches].sum()) )\\\n",
    "                     / (radiant_matches.sum() + dire_matches.sum())\n",
    "            except ZeroDivisionError:\n",
    "                wr = .5\n",
    "            if np.isnan([wr]):\n",
    "                wr = .5\n",
    "            winrates[i, j] = wr - .5\n",
    "            winrates[j, i] = .5 - wr\n",
    "    return winrates\n",
    "\n",
    "def calculate_synergy(X_i, sm):\n",
    "    team1 = 0\n",
    "    team2 = 0\n",
    "    team1_heroes = np.argwhere( X_i[:114])\n",
    "    team2_heroes = np.argwhere( X_i[114:228] )\n",
    "    for i in xrange(4):\n",
    "        for j in xrange(i, 5):\n",
    "            team1 += sm[team1_heroes[i], team1_heroes[j]]\n",
    "            team2 += sm[team2_heroes[i], team2_heroes[j]]\n",
    "    return (team1 - team2)[0]\n",
    "    \n",
    "def calculate_countering(X_i, cm):\n",
    "    team1_heroes = np.argwhere( X_i[:114])\n",
    "    team2_heroes = np.argwhere( X_i[114:228] )\n",
    "    countering = 0\n",
    "    for i in xrange(5):\n",
    "        for j in xrange(5):\n",
    "            try:\n",
    "                countering += cm[team1_heroes[i], team2_heroes[j]]\n",
    "            except IndexError:\n",
    "                import pdb; pdb.set_trace()\n",
    "    return countering[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_cross_val(estimators, X, y, train_size=None):\n",
    "    scores = [[] for est in estimators ]\n",
    "    for i in xrange(5):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=5000)\n",
    "        if train_size:\n",
    "            while True:\n",
    "                X_train, y_train = shuffle(X_train, y_train)\n",
    "                X_train = X_train[:train_size, :]\n",
    "                y_train = y_train[:train_size]\n",
    "                if 1 in y_train and 0 in y_train:\n",
    "                    break\n",
    "        # add countering and synergy\n",
    "        cm = counter_matrix(X_train, y_train)\n",
    "        sm = synergy_matrix(X_train, y_train)\n",
    "        X_train_countering = np.apply_along_axis(lambda x: calculate_countering(x, cm), axis=1, arr=X_train).reshape(-1, 1)\n",
    "        X_train_synergy = np.apply_along_axis(lambda x: calculate_synergy(x, cm), axis=1, arr=X_train).reshape(-1,1)\n",
    "        X_test_countering = np.apply_along_axis(lambda x: calculate_countering(x, cm), axis=1, arr=X_test).reshape(-1, 1)\n",
    "        X_test_synergy = np.apply_along_axis(lambda x: calculate_synergy(x, cm), axis=1, arr=X_test).reshape(-1,1)                \n",
    "        X_train_sc = np.concatenate([X_train, X_train_synergy, X_train_countering], axis=1)\n",
    "        X_test_sc = np.concatenate([X_test, X_test_synergy, X_test_countering], axis=1)\n",
    "        for est in estimators:\n",
    "            est.fit(X_train_sc, y_train)\n",
    "\n",
    "        for i, est in enumerate(estimators):\n",
    "            scores[i].append(est.score(X_test_sc, y_test))\n",
    "    return scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = counter_matrix(X_train, y_train)\n",
    "sm = synergy_matrix(X_train, y_train)\n",
    "X_train_countering = np.apply_along_axis(lambda x: calculate_countering(x, cm), axis=1, arr=X_train).reshape(-1, 1)\n",
    "X_train_synergy = np.apply_along_axis(lambda x: calculate_synergy(x, cm), axis=1, arr=X_train).reshape(-1,1)\n",
    "X_test_countering = np.apply_along_axis(lambda x: calculate_countering(x, cm), axis=1, arr=X_test).reshape(-1, 1)\n",
    "X_test_synergy = np.apply_along_axis(lambda x: calculate_synergy(x, cm), axis=1, arr=X_test).reshape(-1,1)                \n",
    "X_train_sc = np.concatenate([X_train, X_train_synergy, X_train_countering], axis=1)\n",
    "X_test_sc = np.concatenate([X_test, X_test_synergy, X_test_countering], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63660000000000005"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy.stats as stats\n",
    "params = {'n_estimators': stats.geom(p=.005), 'max_leaf_nodes': stats.geom(p=.001),\n",
    "         'max_features': ['log2', 'auto']}\n",
    "rs = RandomizedSearchCV(RandomForestClassifier(), n_iter=50, n_jobs=-1, param_distributions=params)\n",
    "best_model = rs.fit(X_train_sc, y_train)\n",
    "best_model.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63660000000000005"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'max_depth': stats.geom(p=.3), 'reg_alpha' : stats.expon(scale=10)}\n",
    "rs = RandomizedSearchCV(XGBClassifier(), n_iter=50, n_jobs=-1, param_distributions=params)\n",
    "best_xgb = rs.fit(X_train_sc, y_train)\n",
    "best_model.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56459999999999999"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = [LogisticRegression(C=.1), RidgeClassifier(alpha=1000),\n",
    "              RandomForestClassifier(**best_model.best_params_),\n",
    "              XGBClassifier(**best_xgb.best_params_)]\n",
    "scores = my_cross_val(estimators, X, y)\n",
    "mean_scores = map(np.mean, scores)\n",
    "lr_score, ridge_score, rf_score, xgb_score = mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61704 0.62816 0.62772 0.62728\n"
     ]
    }
   ],
   "source": [
    "print(lr_score, ridge_score, rf_score, xgb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'auto', 'max_leaf_nodes': 745, 'n_estimators': 456}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71330927475012884"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59781063720160721"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(**best_model.best_params_), X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_sizes = []\n",
    "test_scores = defaultdict(list)\n",
    "training_size = 4\n",
    "models = {'random_forest': rf, 'logreg': logreg, 'ridge': ridge, 'xgb': xgb}\n",
    "while training_size <= X_train.shape[0]:\n",
    "    training_sizes.append(training_size)\n",
    "    for model_name, model in models.iteritems():\n",
    "        score = model(training_size)\n",
    "        test_scores[model_name].append(score)\n",
    "    training_size = 2 * training_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_sizes.append(X_train.shape[0])\n",
    "for model_name, model in models.iteritems():\n",
    "    score = model(None)\n",
    "    test_scores[model_name].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for model_name, scores in test_scores.iteritems():\n",
    "    ax.plot(training_sizes, scores, label=model_name)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
